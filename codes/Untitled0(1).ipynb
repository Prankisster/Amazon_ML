{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1vBWCwJWYMmjxCBomPfhZdqED7gIYChfM"},"id":"PqHLQ6YLLrWl","outputId":"dff1334c-78a4-40fb-8a85-857d4f5f8e2c"},"outputs":[],"source":["import gensim\n","from gensim import corpora\n","from pprint import pprint\n","import pandas as pd\n","import re\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/AMAZON_ML/clean_new_test_data.csv\")\n","df.fillna(\" \", inplace=True)\n","# df = df.head(10000)\n","keywordsen = []\n","txt = 0\n","t = 0\n","for index, row in df.iterrows():\n","    text = row[\"processed_description\"]\n","    if text == \" \":\n","      txt = row[\"processed_title\"]\n","      text = txt\n","      if txt == \" \":\n","        t = row[\"processed_bullet_points\"]\n","        text = t\n","        if text == \" \":\n","          df = df.drop(index)\n","          continue\n","\n","    print(text)\n","    documents = [text]\n","    tokenized_docs = [doc.lower().split() for doc in documents]\n","    dictionary = corpora.Dictionary(tokenized_docs)\n","    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n","    lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, random_state=42)\n","    topics = lda_model.print_topics(num_words=4)\n","    topic_str = \"\"\n","    for topic in topics:\n","        topic_str += str(topic[1]) + \" \"\n","    print(\"TS\")\n","    print(topic_str)\n","\n","\n","\n","    # Sample string\n","    sample_string = topic_str # 'The \"quick\" brown \"fox\" jumps over the \"lazy\" dog 123.'\n","\n","    # Regular expression pattern to match content within quotation marks that consists only of alphabets\n","    pattern = r'\"([A-Za-z]+)\"'\n","\n","    # Extract all matches of the pattern from the string\n","    matches = re.findall(pattern, sample_string)\n","\n","    # Print the matches\n","    print(\"MATCH\")\n","    print(matches)\n","    Ksen = \"\"\n","\n","    # mainlist = []\n","    for wdr in matches:\n","      Ksen += wdr + \" \"\n","\n","    print(\"KSEN\")\n","    print(Ksen)\n","    keywordsen.append(Ksen)\n","    Ksen = \"\"\n","    # mainlist.append(keywordsen)\n","# print(\"KWS\")\n","# print(mainlist)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEgzexBTRZlc"},"outputs":[],"source":["df[\"KEY_SEN\"]=keywordsen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNeUFjD7Rg4H"},"outputs":[],"source":["df.to_csv(\"Check_test.csv\", index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPmhyKjy+gduKIBtSldSqJx","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}