{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Of2Q5jwBv2fr-kcQd7leepEFVVwIKfb_","authorship_tag":"ABX9TyP+jNmJmGvJsbCbc75AwRSJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Is829KS-nhR5","executionInfo":{"status":"ok","timestamp":1682152817776,"user_tz":-330,"elapsed":5882,"user":{"displayName":"Social Media","userId":"08430438303547795979"}}},"outputs":[],"source":["import pandas as pd\n","\n","import xgboost as xgb\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.svm import SVR\n","from sklearn.linear_model import Lasso\n","\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","\n","from sklearn.metrics import mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"markdown","source":["**Data Frame & Data split**"],"metadata":{"id":"hqZFtjoDoQ_Z"}},{"cell_type":"code","source":["\n","pd.set_option('display.max_rows', None)\n","\n","# Load the data into a pandas dataframe\n","data = pd.read_csv(\"/content/drive/MyDrive/AMZ_ML/Dataset/datasetb2d9982/dataset/train.csv\")\n","\n","# Split the data into training and testing sets\n","train_data, test_data, train_labels, test_labels = train_test_split(data.drop(\"PRODUCT_LENGTH\", axis=1), data[\"PRODUCT_LENGTH\"], test_size=0.2)\n","\n"],"metadata":{"id":"E1w8Gx62oPf8","executionInfo":{"status":"ok","timestamp":1682152867692,"user_tz":-330,"elapsed":49924,"user":{"displayName":"Social Media","userId":"08430438303547795979"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"wQyBtQ_HHS6v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.   **Tokenization:** This involves splitting the text data into individual words,which will later be used as the features for the model.\n","\n","2.   **Stopword Removal:** Stopwords are common words in the English language (e.g. 'the', 'and', 'a') that add little meaning to the text data. Removing them can improve the performance of the model.\n","\n","3. **Stemming or Lemmatization:** These are techniques used to reduce the words to their base form (e.g. 'running' to 'run'). This can help reduce the number of unique features and improve the accuracy of the model.\n","\n","4. **Vectorization:** Once the text data has been preprocessed, it needs to be transformed into a numerical representation that can be used by regression models. One common technique for this is using a bag-of-words model, where each word in the text is treated as a feature and its frequency in the document is used as its value.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Eca9PNqzI74Z"}},{"cell_type":"markdown","source":["**randomForest**"],"metadata":{"id":"WMZRD55bn9ks"}},{"cell_type":"code","source":["# Define the random forest regressor model\n","rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n","\n","# Fit the model on the training data\n","rf.fit(train_data, train_labels)\n","\n","# Predict the product length for the test data\n","predictions = rf.predict(test_data)\n","\n","# Calculate the mean absolute percentage error (MAPE) of the predictions\n","mape = mean_absolute_percentage_error(test_labels, predictions)\n","\n","# Calculate the score using the specified evaluation metric\n","score = max(0, 100 * (1 - mape))\n","\n","# Print the score\n","print(\"Score: %.2f\" % score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"_yr-k-6fn7-s","executionInfo":{"status":"error","timestamp":1682098184752,"user_tz":-330,"elapsed":1259,"user":{"displayName":"Social Media","userId":"08430438303547795979"}},"outputId":"19c807aa-61d9-414b-add6-31ca79b34689"},"execution_count":6,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-280adf159b27>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict the product length for the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"FancyDressWale Girl's Unicorn Polyester and Cotton Mix Birthday Princess Rainbow Tutu Skirt, White T-Shirt and Assorted Head Band\""]}]},{"cell_type":"markdown","source":["**linearRegression**"],"metadata":{"id":"o3n96hSipOn3"}},{"cell_type":"code","source":["# Define the linear regression model\n","lr = LinearRegression()\n","\n","# Fit the model on the training data\n","lr.fit(train_data, train_labels)\n","\n","# Predict the product length for the test data\n","predictions = lr.predict(test_data)\n","\n","# Calculate the mean absolute percentage error (MAPE) of the predictions\n","mape = mean_absolute_percentage_error(test_labels, predictions)\n","\n","# Calculate the score using the specified evaluation metric\n","score = max(0, 100 * (1 - mape))\n","\n","# Print the score\n","print(\"Score: %.2f\" % score)"],"metadata":{"id":"4JQ6LiPBpSGb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**decisionTree**"],"metadata":{"id":"1s0qq7LYpzba"}},{"cell_type":"code","source":["# Define the decision tree regressor model\n","dt = DecisionTreeRegressor(max_depth=10, random_state=42)\n","\n","# Fit the model on the training data\n","dt.fit(train_data, train_labels)\n","\n","# Predict the product length for the test data\n","predictions = dt.predict(test_data)\n","\n","# Calculate the mean absolute percentage error (MAPE) of the predictions\n","mape = mean_absolute_percentage_error(test_labels, predictions)\n","\n","# Calculate the score using the specified evaluation metric\n","score = max(0, 100 * (1 - mape))\n","\n","# Print the score\n","print(\"Score: %.2f\" % score)"],"metadata":{"id":"dANtkPaGp1Yw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**xgboost**"],"metadata":{"id":"VdlxJ8giqjpE"}},{"cell_type":"code","source":["# Define the XGBoost regressor model\n","xgb_model = xgb.XGBRegressor(objective='reg:squarederror', max_depth=5, n_estimators=100)\n","\n","# Fit the model on the training data\n","xgb_model.fit(train_data, train_labels)\n","\n","# Predict the product length for the test data\n","predictions = xgb_model.predict(test_data)\n","\n","# Calculate the mean absolute percentage error (MAPE) of the predictions\n","mape = mean_absolute_percentage_error(test_labels, predictions)\n","\n","# Calculate the score using the specified evaluation metric\n","score = max(0, 100 * (1 - mape))\n","\n","# Print the score\n","print(\"Score: %.2f\" % score)"],"metadata":{"id":"MJ0c3IpMqnZ7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**adaboost**"],"metadata":{"id":"_uKg53IlrL4F"}},{"cell_type":"code","source":["# Define the AdaBoost regressor model\n","ada_model = AdaBoostRegressor(n_estimators=50)\n","\n","# Fit the model on the training data\n","ada_model.fit(train_data, train_labels)\n","\n","# Predict the product length for the test data\n","predictions = ada_model.predict(test_data)\n","\n","# Calculate the mean absolute percentage error (MAPE) of the predictions\n","mape = mean_absolute_percentage_error(test_labels, predictions)\n","\n","# Calculate the score using the specified evaluation metric\n","score = max(0, 100 * (1 - mape))\n","\n","# Print the score\n","print(\"Score: %.2f\" % score)"],"metadata":{"id":"YgZTh1jErOE3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**supportVector**"],"metadata":{"id":"Pd_JTI2-t44S"}},{"cell_type":"code","source":["# Initialize the SVR model with default hyperparameters\n","svr_model = SVR(kernel = \"rbf\")\n","\n","# Train the SVR model on the training data\n","svr_model.fit(train_data, train_labels)\n","\n","# Make predictions on the test set\n","predictions = svr_model.predict(test_data)\n","\n","# Evaluate the model using mean absolute percentage error\n","score = max(0, 100*(1-mean_absolute_percentage_error(test_labels, predictions)))\n","print('Score:', score)"],"metadata":{"id":"HdfPSSH6uDIm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**lassoRegression**"],"metadata":{"id":"jKHO31mCu0DL"}},{"cell_type":"code","source":["# Create and train the model\n","lasso_model = Lasso(alpha=0.1)\n","lasso_model.fit(train_data, train_labels)\n","\n","# Make predictions on the test set\n","predictions = lasso_model.predict(test_data)\n","\n","# Calculate the evaluation metric\n","score = max(0, 100*(1-mean_absolute_percentage_error(test_labels, predictions)))\n","\n","# Print the score\n","print(\"Lasso Regression score: {:.2f}\".format(score))\n","\n","# with preprocessing\n","\n","# # Define the column transformer to encode the categorical variables\n","# preprocessor = ColumnTransformer(\n","#     transformers=[\n","#         ('onehot', OneHotEncoder(handle_unknown='ignore'), ['PRODUCT_TYPE_ID'])\n","#     ])\n","\n","# # Fit and transform the training data\n","# X_train_encoded = preprocessor.fit_transform(X_train)\n","# X_test_encoded = preprocessor.transform(X_test)\n","\n","# # Scale the numerical variables using StandardScaler\n","# scaler = StandardScaler()\n","# X_train_scaled = scaler.fit_transform(X_train[['PRODUCT_LENGTH']])\n","# X_test_scaled = scaler.transform(X_test[['PRODUCT_LENGTH']])\n","\n","# # Combine the encoded and scaled features\n","# X_train_final = pd.concat([pd.DataFrame(X_train_encoded.toarray()), pd.DataFrame(X_train_scaled)], axis=1)\n","# X_test_final = pd.concat([pd.DataFrame(X_test_encoded.toarray()), pd.DataFrame(X_test_scaled)], axis=1)\n","\n","# # Create and train the model\n","# lasso_model = Lasso(alpha=0.1)\n","# lasso_model.fit(X_train_final, y_train)\n","\n","# # Make predictions on the test set\n","# y_pred = lasso_model.predict(X_test_final)\n","\n","# # Calculate the evaluation metric\n","# score = max(0, 100*(1-mean_absolute_percentage_error(y_test, y_pred)))\n","\n","# # Print the score\n","# print(\"Lasso Regression score: {:.2f}\".format(score))"],"metadata":{"id":"b0K6S6yyu2GX"},"execution_count":null,"outputs":[]}]}